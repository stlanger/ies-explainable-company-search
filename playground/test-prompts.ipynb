{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c25d38a1-0775-4902-8e8e-dabacbbca451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device 0: NVIDIA RTX 6000 Ada Generation\n",
      "using cuda as device\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import json\n",
    "import re\n",
    "import torch\n",
    "\n",
    "from rag_utils import RAG_Utils\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        print(f\"Device {i}: {torch.cuda.get_device_name(i)}\")\n",
    "else:\n",
    "    print(\"CUDA is not available.\")\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "print(f\"using {device} as device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38cd25c6-a969-45b7-8550-59cc23b4ee88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cbc5240d-fbd7-4a60-9ec0-83530b21e31c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f0c4713ef824990acd6ec3fce29bd70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "llm_model_name = \"meta-llama/Meta-Llama-3.1-8B-Instruct\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(llm_model_name)    \n",
    "pipeline = transformers.pipeline(\n",
    "    \"text-generation\",\n",
    "    model=llm_model_name,\n",
    "    model_kwargs={\"torch_dtype\": torch.bfloat16},\n",
    "    device_map=\"auto\",\n",
    "    temperature=0.3,\n",
    "    top_p=0.9,\n",
    "    pad_token_id=tokenizer.eos_token_id,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d163062b-79a2-405a-a7d1-f85bcb640de1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our team of expert cyber security specialists provides emergency data recovery services to businesses in the UK, helping to decrypt and restore access to encrypted data. \n",
      "\n",
      "At CyberGuard, we offer a comprehensive incident response service, designed to mitigate the impact of a data breach and get your business back up and running as quickly as possible. \n",
      "\n",
      "Our data recovery experts have extensive experience in dealing with ransomware attacks and can help you to negotiate with attackers, recover your data and prevent future breaches. \n",
      "\n",
      "Our IT support services are designed to provide businesses in the UK with a robust and reliable IT infrastructure, including regular security audits and penetration testing to identify potential vulnerabilities. \n",
      "\n",
      "Our emergency data recovery service is available 24/7, with a rapid response team that can be on site within hours to assess the situation and begin the process of decrypting and recovering your data.\n"
     ]
    }
   ],
   "source": [
    "sys_prompt = \"\"\"Given a user query describing a problem, need, or desired expertise, generate 5 example sentences that realistically match what companies in the United Kingdom \n",
    "might write on their websites to describe services or offerings relevant to that query. Use natural, professional British English in the tone of typical company website copy. \n",
    "Focus on how companies describe what they do, what makes their service valuable, and how customers can engage with them. The goal is for these sentences to serve as semantically compatible search \n",
    "queries for retrieving matching company website content from a vector store. Do not include any introductory or explanatory textâ€”only output the example sentences.\n",
    "Do not number the sentences, instead just put each of them on a new line.\"\"\"\n",
    "\n",
    "user_prompt = \"\"\"My company's infrastructure has been hacked and all my data is encrypted. Who can help me?\"\"\"\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": sys_prompt},\n",
    "    {\"role\": \"user\", \"content\": user_prompt},\n",
    "]\n",
    "\n",
    "outputs = pipeline(\n",
    "    messages,\n",
    "    max_new_tokens=256,\n",
    ")\n",
    "\n",
    "answer = outputs[0][\"generated_text\"][-1][\"content\"]\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "857afe4b-57f7-4a22-b7a3-8b16282ed915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: configparser in /home/dev/.local/lib/python3.10/site-packages (7.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install configparser\n",
    "from configparser import ConfigParser"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
